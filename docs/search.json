[
  {
    "objectID": "HW9.html",
    "href": "HW9.html",
    "title": "HW9",
    "section": "",
    "text": "library(tidyr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(readr)\nlibrary(lubridate)\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\nlibrary(psych)\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n\n\n✔ broom        1.0.6     ✔ recipes      1.1.0\n✔ dials        1.3.0     ✔ rsample      1.2.1\n✔ ggplot2      3.5.1     ✔ tibble       3.2.1\n✔ infer        1.0.7     ✔ tune         1.2.1\n✔ modeldata    1.4.0     ✔ workflows    1.1.4\n✔ parsnip      1.2.1     ✔ workflowsets 1.1.0\n✔ purrr        1.0.2     ✔ yardstick    1.3.1\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ ggplot2::%+%()    masks psych::%+%()\n✖ ggplot2::alpha()  masks scales::alpha(), psych::alpha()\n✖ purrr::discard()  masks scales::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(stats)\nlibrary(rsample)\nlibrary(yardstick)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats 1.0.0     ✔ stringr 1.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ ggplot2::%+%()       masks psych::%+%()\n✖ ggplot2::alpha()     masks scales::alpha(), psych::alpha()\n✖ scales::col_factor() masks readr::col_factor()\n✖ purrr::discard()     masks scales::discard()\n✖ dplyr::filter()      masks stats::filter()\n✖ stringr::fixed()     masks recipes::fixed()\n✖ dplyr::lag()         masks stats::lag()\n✖ yardstick::spec()    masks readr::spec()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(corrr)\nlibrary(parsnip)\nlibrary(tune)\nlibrary(glmnet)\n\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-8\n\nlibrary(baguette)\nlibrary(ranger)"
  },
  {
    "objectID": "HW9.html#reading-in-data",
    "href": "HW9.html#reading-in-data",
    "title": "HW9",
    "section": "Reading in Data",
    "text": "Reading in Data\n\ndata&lt;-readr::read_csv(\"SeoulBikeData.csv\",locale=locale(encoding=\"latin1\"))\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "HW9.html#checking-for-missing-values",
    "href": "HW9.html#checking-for-missing-values",
    "title": "HW9",
    "section": "Checking for Missing Values",
    "text": "Checking for Missing Values\n\nAfter checking to see if how many missing values we have in each columns we can see that there aren’t any missing values.\n\nsum_na&lt;-function(column){\n  sum(is.na(column))\n}\n\nna_counts&lt;-data|&gt;\n  summarize(across(everything(),sum_na))\nprint(na_counts)\n\n# A tibble: 1 × 14\n   Date `Rented Bike Count`  Hour `Temperature(°C)` `Humidity(%)`\n  &lt;int&gt;               &lt;int&gt; &lt;int&gt;             &lt;int&gt;         &lt;int&gt;\n1     0                   0     0                 0             0\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;int&gt;, `Visibility (10m)` &lt;int&gt;,\n#   `Dew point temperature(°C)` &lt;int&gt;, `Solar Radiation (MJ/m2)` &lt;int&gt;,\n#   `Rainfall(mm)` &lt;int&gt;, `Snowfall (cm)` &lt;int&gt;, Seasons &lt;int&gt;, Holiday &lt;int&gt;,\n#   `Functioning Day` &lt;int&gt;"
  },
  {
    "objectID": "HW9.html#exploring-basic-summariesvalues",
    "href": "HW9.html#exploring-basic-summariesvalues",
    "title": "HW9",
    "section": "Exploring Basic Summaries/Values",
    "text": "Exploring Basic Summaries/Values\n\nOne of the things that sticks out to me is that each variable has the same number of observations which confirms there aren’t any missing values. We can also see which variables are numeric or not. Finally I can see that I’ll need to rename the variables to make them more user friendly.\n\npsych::describe(data)\n\n                          vars    n    mean     sd  median trimmed    mad   min\nDate*                        1 8760  183.00 105.37  183.00  183.00 134.92   1.0\nRented Bike Count            2 8760  704.60 645.00  504.50  612.58 553.75   0.0\nHour                         3 8760   11.50   6.92   11.50   11.50   8.90   0.0\nTemperature(°C)              4 8760   12.88  11.94   13.70   13.19  13.94 -17.8\nHumidity(%)                  5 8760   58.23  20.36   57.00   58.02  23.72   0.0\nWind speed (m/s)             6 8760    1.72   1.04    1.50    1.63   1.04   0.0\nVisibility (10m)             7 8760 1436.83 608.30 1698.00 1509.50 447.75  27.0\nDew point temperature(°C)    8 8760    4.07  13.06    5.10    4.76  14.38 -30.6\nSolar Radiation (MJ/m2)      9 8760    0.57   0.87    0.01    0.38   0.01   0.0\nRainfall(mm)                10 8760    0.15   1.13    0.00    0.00   0.00   0.0\nSnowfall (cm)               11 8760    0.08   0.44    0.00    0.00   0.00   0.0\nSeasons*                    12 8760    2.50   1.11    2.00    2.49   1.48   1.0\nHoliday*                    13 8760    1.95   0.22    2.00    2.00   0.00   1.0\nFunctioning Day*            14 8760    1.97   0.18    2.00    2.00   0.00   1.0\n                              max   range  skew kurtosis   se\nDate*                      365.00  364.00  0.00    -1.20 1.13\nRented Bike Count         3556.00 3556.00  1.15     0.85 6.89\nHour                        23.00   23.00  0.00    -1.20 0.07\nTemperature(°C)             39.40   57.20 -0.20    -0.84 0.13\nHumidity(%)                 98.00   98.00  0.06    -0.80 0.22\nWind speed (m/s)             7.40    7.40  0.89     0.73 0.01\nVisibility (10m)          2000.00 1973.00 -0.70    -0.96 6.50\nDew point temperature(°C)   27.20   57.80 -0.37    -0.76 0.14\nSolar Radiation (MJ/m2)      3.52    3.52  1.50     1.12 0.01\nRainfall(mm)                35.00   35.00 14.53   284.76 0.01\nSnowfall (cm)                8.80    8.80  8.44    93.73 0.00\nSeasons*                     4.00    3.00  0.00    -1.35 0.01\nHoliday*                     2.00    1.00 -4.16    15.33 0.00\nFunctioning Day*             2.00    1.00 -5.17    24.72 0.00"
  },
  {
    "objectID": "HW9.html#here-we-are-updating-our-data-set.",
    "href": "HW9.html#here-we-are-updating-our-data-set.",
    "title": "HW9",
    "section": "Here we are updating our data set.",
    "text": "Here we are updating our data set.\n\n#Fixing the Date variable\ndata$Date&lt;- dmy(data$Date)\n\n\n#Here we are changing our categorical variables to be factors.\ndata&lt;-data|&gt;\n  mutate(Seasons=as.factor(Seasons),\n         Holiday=as.factor(Holiday),\n         `Functioning Day`=as.factor(`Functioning Day`))\n\n#Here we are updating the varaible names to make them more user friendly. \n\ndata&lt;-data|&gt;\n  rename(temp=`Temperature(°C)`,hr=Hour,humidity=`Humidity(%)`,rbc=`Rented Bike Count`,ws=`Wind speed (m/s)`,vis=`Visibility (10m)`,dpttemp=`Dew point temperature(°C)`,solrad=`Solar Radiation (MJ/m2)`,rain=`Rainfall(mm)`,snow=`Snowfall (cm)`,holiday=Holiday,season=Seasons,funday=`Functioning Day`)"
  },
  {
    "objectID": "HW9.html#creating-summaries-across-categorical-variables",
    "href": "HW9.html#creating-summaries-across-categorical-variables",
    "title": "HW9",
    "section": "Creating Summaries Across Categorical variables",
    "text": "Creating Summaries Across Categorical variables"
  },
  {
    "objectID": "HW9.html#manipulating-the-original-data-set-that-we-will-use-for-analysis.",
    "href": "HW9.html#manipulating-the-original-data-set-that-we-will-use-for-analysis.",
    "title": "HW9",
    "section": "Manipulating the original data set that we will use for analysis.",
    "text": "Manipulating the original data set that we will use for analysis.\n\nModel_data&lt;-data|&gt;\n  group_by(Date,season,holiday)|&gt;\n   summarize(\n     sum_rbc=sum(rbc,na.rm=TRUE),\n     sum_rain=sum(rain,na.rm=TRUE),\n     sum_snow=sum(snow,na.rm=TRUE),\n     mean_temp=mean(temp,na.rm=TRUE),\n     mean_hum=mean(humidity,na.rm=TRUE),\n     mean_ws=mean(ws,na.rm=TRUE),\n     mean_vis=mean(vis,na.rm=TRUE),\n     mean_dpttemp=mean(dpttemp,na.rm=TRUE),\n     mean_solrad=mean(solrad,na.rm=TRUE),\n   )|&gt;\n  ungroup()\n\n`summarise()` has grouped output by 'Date', 'season'. You can override using\nthe `.groups` argument."
  },
  {
    "objectID": "HW9.html#recreating-the-summaries-from-above-with-the-new-model-data.",
    "href": "HW9.html#recreating-the-summaries-from-above-with-the-new-model-data.",
    "title": "HW9",
    "section": "Recreating the summaries from above with the new model data.",
    "text": "Recreating the summaries from above with the new model data.\n\nModel_data|&gt;\n  group_by(holiday,season)|&gt;\n  summarise(across(where(is.numeric),\n                   list(\"sum\"=sum,\"mean\"=mean,\"median\"=median,\"sd\"=sd,\"min\"=min,\"max\"=max),\n                   .names=\"{.fn}_{.col}\"))\n\n`summarise()` has grouped output by 'holiday'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 56\n# Groups:   holiday [2]\n  holiday  season sum_sum_rbc mean_sum_rbc median_sum_rbc sd_sum_rbc min_sum_rbc\n  &lt;fct&gt;    &lt;fct&gt;        &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;\n1 Holiday  Autumn       91018       18204.         20060      11288.           0\n2 Holiday  Spring       45742       15247.         13790      10917.        5132\n3 Holiday  Summer       49063       24532.         24532.      8438.       18565\n4 Holiday  Winter       30072        3759           3454.      1561.        2014\n5 No Holi… Autumn     1698984       19756.         21573       9349.           0\n6 No Holi… Spring     1566167       17597.         17450       8653.           0\n7 No Holi… Summer     2234171       24824.         25572.      7324.        3231\n8 No Holi… Winter      457097        5574.          5609       1757.        2487\n# ℹ 49 more variables: max_sum_rbc &lt;dbl&gt;, sum_sum_rain &lt;dbl&gt;,\n#   mean_sum_rain &lt;dbl&gt;, median_sum_rain &lt;dbl&gt;, sd_sum_rain &lt;dbl&gt;,\n#   min_sum_rain &lt;dbl&gt;, max_sum_rain &lt;dbl&gt;, sum_sum_snow &lt;dbl&gt;,\n#   mean_sum_snow &lt;dbl&gt;, median_sum_snow &lt;dbl&gt;, sd_sum_snow &lt;dbl&gt;,\n#   min_sum_snow &lt;dbl&gt;, max_sum_snow &lt;dbl&gt;, sum_mean_temp &lt;dbl&gt;,\n#   mean_mean_temp &lt;dbl&gt;, median_mean_temp &lt;dbl&gt;, sd_mean_temp &lt;dbl&gt;,\n#   min_mean_temp &lt;dbl&gt;, max_mean_temp &lt;dbl&gt;, sum_mean_hum &lt;dbl&gt;, …"
  },
  {
    "objectID": "HW9.html#finding-the-correlation-between-all-numeric-variables-grouped-by-holiday-and-season",
    "href": "HW9.html#finding-the-correlation-between-all-numeric-variables-grouped-by-holiday-and-season",
    "title": "HW9",
    "section": "Finding the correlation between all numeric variables grouped by holiday and season",
    "text": "Finding the correlation between all numeric variables grouped by holiday and season\n\nCorrelation &lt;- Model_data |&gt;\n   group_by(holiday,season)|&gt;\n  correlate()\n\nNon-numeric variables removed from input: `Date`, `season`, and `holiday`\nCorrelation computed with\n• Method: 'pearson'\n• Missing treated using: 'pairwise.complete.obs'"
  },
  {
    "objectID": "HW9.html#here-is-a-visual-representation-for-the-number-of-holidays-broken-down-by-season",
    "href": "HW9.html#here-is-a-visual-representation-for-the-number-of-holidays-broken-down-by-season",
    "title": "HW9",
    "section": "Here is a visual representation for the number of holidays broken down by season",
    "text": "Here is a visual representation for the number of holidays broken down by season\n\ng &lt;- ggplot(data = Model_data , aes(x = season, fill = holiday))\ng + geom_bar()+\n labs(x = \"Season\")"
  },
  {
    "objectID": "HW9.html#here-i-thought-it-was-interesting-to-see-the-relationship-between-the-temperture-season-and-bike-rentals.",
    "href": "HW9.html#here-i-thought-it-was-interesting-to-see-the-relationship-between-the-temperture-season-and-bike-rentals.",
    "title": "HW9",
    "section": "Here I thought it was interesting to see the relationship between the temperture, season, and bike rentals.",
    "text": "Here I thought it was interesting to see the relationship between the temperture, season, and bike rentals.\n\ng &lt;- ggplot(Model_data,\n aes(x = mean_temp, y = sum_rbc, color = season))\ng + geom_point()"
  },
  {
    "objectID": "HW9.html#splitting-the-data-on-a-7525-split.",
    "href": "HW9.html#splitting-the-data-on-a-7525-split.",
    "title": "HW9",
    "section": "Splitting the data on a 75/25 split.",
    "text": "Splitting the data on a 75/25 split.\n\ndata_split&lt;-initial_split(Model_data,strata=season,prop=0.75)\ndata_training&lt;-training(data_split)\ndata_test&lt;-testing(data_split)\ndata_fold&lt;-vfold_cv(data_training,10)\n\nprint(data_training)\n\n# A tibble: 273 × 12\n   Date       season holiday    sum_rbc sum_rain sum_snow mean_temp mean_hum\n   &lt;date&gt;     &lt;fct&gt;  &lt;fct&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 2018-09-01 Autumn No Holiday   26010      0          0      25.5     61.2\n 2 2018-09-02 Autumn No Holiday   26881      0          0      25.0     54.5\n 3 2018-09-03 Autumn No Holiday   10802     34.5        0      23.6     82.2\n 4 2018-09-04 Autumn No Holiday   29529      0          0      23.3     71.6\n 5 2018-09-05 Autumn No Holiday   31114      0          0      23.8     61.8\n 6 2018-09-06 Autumn No Holiday   27838      0          0      24.2     70.8\n 7 2018-09-07 Autumn No Holiday   30381      1.5        0      22.2     56.9\n 8 2018-09-08 Autumn No Holiday   29813      0          0      21.7     48.7\n 9 2018-09-09 Autumn No Holiday   28354      0          0      22.0     49.5\n10 2018-09-11 Autumn No Holiday   31694      0          0      21.6     48.0\n# ℹ 263 more rows\n# ℹ 4 more variables: mean_ws &lt;dbl&gt;, mean_vis &lt;dbl&gt;, mean_dpttemp &lt;dbl&gt;,\n#   mean_solrad &lt;dbl&gt;\n\nprint(data_test)\n\n# A tibble: 92 × 12\n   Date       season holiday    sum_rbc sum_rain sum_snow mean_temp mean_hum\n   &lt;date&gt;     &lt;fct&gt;  &lt;fct&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 2017-12-06 Winter No Holiday    6669      1.3      8.6    0.0458     70.8\n 2 2017-12-07 Winter No Holiday    8549      0       10.4    1.09       67.5\n 3 2017-12-15 Winter No Holiday    7198      0        0     -3.28       50.5\n 4 2017-12-19 Winter No Holiday    4334      0       55.6   -3.53       50.2\n 5 2017-12-20 Winter No Holiday    4568      0.2     48.3   -4.29       65.5\n 6 2017-12-22 Winter Holiday       7184      0        7.7    2.76       67.1\n 7 2017-12-26 Winter No Holiday    5605      0        0     -3.27       43.6\n 8 2018-01-04 Winter No Holiday    6453      0        0     -4.8        44.1\n 9 2018-01-09 Winter No Holiday    5500      0       10.8   -3.87       58.6\n10 2018-01-15 Winter No Holiday    6334      0.2      0      4.71       63.9\n# ℹ 82 more rows\n# ℹ 4 more variables: mean_ws &lt;dbl&gt;, mean_vis &lt;dbl&gt;, mean_dpttemp &lt;dbl&gt;,\n#   mean_solrad &lt;dbl&gt;"
  },
  {
    "objectID": "HW9.html#creating-a-10-fold-cv-split-on-the-training-set",
    "href": "HW9.html#creating-a-10-fold-cv-split-on-the-training-set",
    "title": "HW9",
    "section": "Creating a 10 fold cv split on the training set",
    "text": "Creating a 10 fold cv split on the training set\n\nget_cv_splits &lt;- function(data, num_folds){\n  #get fold size\n  size_fold &lt;- floor(nrow(data)/num_folds)\n  #get random indices to subset the data with\n  random_indices &lt;- sample(1:nrow(data), size = nrow(data), replace = FALSE)\n  #create a list to save our folds in\n  folds &lt;- list()\n  #now cycle through our random indices vector and take the appropriate observations to each fold\n  for(i in 1:num_folds){\n    if (i &lt; num_folds) {\n      fold_index &lt;- seq(from = (i-1)*size_fold +1, to = i*size_fold, by = 1)\n      folds[[i]] &lt;- data[random_indices[fold_index], ]\n    } else {\n      fold_index &lt;- seq(from = (i-1)*size_fold +1, to = length(random_indices), by = 1)\n      folds[[i]] &lt;- data[random_indices[fold_index], ]\n    }\n  }\n  return(folds)\n}\nfolds &lt;- get_cv_splits(data_training, 10)"
  },
  {
    "objectID": "HW9.html#creating-a-model-for-recipe-1",
    "href": "HW9.html#creating-a-model-for-recipe-1",
    "title": "HW9",
    "section": "Creating a model for recipe 1",
    "text": "Creating a model for recipe 1\n\nrec1&lt;-recipe(sum_rbc~.,data=data_training)|&gt;\n  step_date(Date,features=\"dow\")|&gt;\n  step_mutate(DOW=factor(if_else(Date_dow %in% c(\"Sat\",\"Sun\"),\"Weekend\",\"Weekday\")))|&gt;\n  step_rm(Date,Date_dow)|&gt;\n  step_dummy(season,holiday,DOW)|&gt;\n  step_normalize(all_numeric(),-all_outcomes())"
  },
  {
    "objectID": "HW9.html#creating-a-model-for-recipe-2",
    "href": "HW9.html#creating-a-model-for-recipe-2",
    "title": "HW9",
    "section": "Creating a model for recipe 2",
    "text": "Creating a model for recipe 2\n\nrec2&lt;-recipe(sum_rbc~.,data=data_training)|&gt;\n  update_role(Date,new_role = \"ID\")|&gt;\n  step_date(Date,features=\"dow\")|&gt;\n step_mutate(DOW=factor(if_else(Date_dow %in% c(\"Sat\",\"Sun\"),\"Weekend\",\"Weekday\")))|&gt;\n  step_rm(Date,Date_dow)|&gt;\n  step_dummy(season,holiday,DOW)|&gt;\n  step_normalize(all_numeric(),-all_outcomes())|&gt;\n  step_interact(terms = ~starts_with(\"holiday\")*starts_with(\"season\")+mean_temp*sum_rain+mean_temp*starts_with(\"season\"))"
  },
  {
    "objectID": "HW9.html#creating-a-model-for-recipe-3",
    "href": "HW9.html#creating-a-model-for-recipe-3",
    "title": "HW9",
    "section": "Creating a model for recipe 3",
    "text": "Creating a model for recipe 3\n\nrec3&lt;-recipe(sum_rbc~.,data=data_training)|&gt;\n  update_role(Date,new_role = \"ID\")|&gt;\n  step_date(Date,features=\"dow\")|&gt;\n step_mutate(DOW=factor(if_else(Date_dow %in% c(\"Sat\",\"Sun\"),\"Weekend\",\"Weekday\")))|&gt;\n  step_rm(Date,Date_dow)|&gt;\n  step_dummy(season,holiday,DOW)|&gt;\n  step_normalize(all_numeric(),-all_outcomes())|&gt;\n  step_interact(terms = ~starts_with(\"holiday\")*starts_with(\"season\")+mean_temp*sum_rain+mean_temp*starts_with(\"season\"))|&gt;\n  step_poly(mean_temp,mean_ws,mean_vis,mean_dpttemp,mean_solrad,sum_rain,sum_snow,degree=2)"
  },
  {
    "objectID": "HW9.html#model-for-recipe-1",
    "href": "HW9.html#model-for-recipe-1",
    "title": "HW9",
    "section": "Model for Recipe 1",
    "text": "Model for Recipe 1\n\nmodel&lt;-linear_reg() %&gt;%\n  set_engine(\"lm\")\n\n\ncvFit1&lt;-workflow()|&gt;\n  add_recipe(rec1)|&gt;\n  add_model(model)|&gt;\n  fit_resamples(data_fold)\n\ncvFit2&lt;-workflow()|&gt;\n  add_recipe(rec2)|&gt;\n  add_model(model)|&gt;\n  fit_resamples(data_fold)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\ncvFit3&lt;-workflow()|&gt;\n  add_recipe(rec3)|&gt;\n  add_model(model)|&gt;\n  fit_resamples(data_fold)\n\n→ A | warning: prediction from rank-deficient fit; consider predict(., rankdeficient=\"NA\")\n\n\nThere were issues with some computations   A: x1\nThere were issues with some computations   A: x1\n\n\n\n\nmetrics&lt;-rbind(cvFit1 |&gt; collect_metrics(),\n      cvFit2 |&gt; collect_metrics(),\n      cvFit3 |&gt; collect_metrics()\n  \n)\n\nffit&lt;-workflow()|&gt;\n  add_recipe(rec1)|&gt;\n  add_model(model)|&gt;\n  last_fit(data_split)\n\nffit|&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    6153.    Preprocessor1_Model1\n2 rsq     standard       0.648 Preprocessor1_Model1\n\nffit|&gt;\n  extract_fit_parsnip()|&gt;\n  tidy()\n\n# A tibble: 14 × 5\n   term               estimate std.error statistic   p.value\n   &lt;chr&gt;                 &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)          16899.      341.    49.6   2.97e-134\n 2 sum_rain             -1803.      455.    -3.96  9.61e-  5\n 3 sum_snow              -273.      368.    -0.743 4.58e-  1\n 4 mean_temp             1524.     6402.     0.238 8.12e-  1\n 5 mean_hum              -588.     2447.    -0.240 8.10e-  1\n 6 mean_ws               -875.      388.    -2.25  2.50e-  2\n 7 mean_vis              -294.      485.    -0.606 5.45e-  1\n 8 mean_dpttemp          1575.     7580.     0.208 8.36e-  1\n 9 mean_solrad           4082.      633.     6.45  5.60e- 10\n10 season_Spring        -1897.      485.    -3.91  1.18e-  4\n11 season_Summer         -325.      564.    -0.576 5.65e-  1\n12 season_Winter        -3061.      654.    -4.68  4.62e-  6\n13 holiday_No.Holiday     799.      351.     2.27  2.37e-  2\n14 DOW_Weekend           -686.      348.    -1.97  4.96e-  2"
  },
  {
    "objectID": "HW9.html#lasso-model",
    "href": "HW9.html#lasso-model",
    "title": "HW9",
    "section": "LASSO Model",
    "text": "LASSO Model\n\nlibrary(shape)\n\nLASSO&lt;-linear_reg(penalty = tune(),mixture=1)|&gt;\n  set_engine(\"glmnet\")\n\nLASSO_wkf&lt;- workflow()|&gt;\n  add_recipe(rec1)|&gt;\n  add_model(LASSO)\n  LASSO_wkf\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_dummy()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = tune()\n  mixture = 1\n\nComputational engine: glmnet \n\n  LASSO_grid&lt;-LASSO_wkf|&gt;\n    tune_grid(resamples = data_fold,\n              grid=grid_regular(penalty(),levels=200))\n  \n  LASSO_grid\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics           .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;             &lt;list&gt;          \n 1 &lt;split [245/28]&gt; Fold01 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [245/28]&gt; Fold02 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [245/28]&gt; Fold03 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [246/27]&gt; Fold04 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [246/27]&gt; Fold05 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [246/27]&gt; Fold06 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [246/27]&gt; Fold07 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [246/27]&gt; Fold08 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [246/27]&gt; Fold09 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [246/27]&gt; Fold10 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n\n  #A warning will occur for one value of the tuning parameter, safe to ignore\nLASSO_grid &lt;- LASSO_wkf |&gt;\n  tune_grid(resamples = data_fold,\n            grid = grid_regular(penalty(), levels = 200)) \n\nLASSO_grid\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics           .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;             &lt;list&gt;          \n 1 &lt;split [245/28]&gt; Fold01 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [245/28]&gt; Fold02 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [245/28]&gt; Fold03 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [246/27]&gt; Fold04 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [246/27]&gt; Fold05 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [246/27]&gt; Fold06 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [246/27]&gt; Fold07 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [246/27]&gt; Fold08 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [246/27]&gt; Fold09 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [246/27]&gt; Fold10 &lt;tibble [400 × 5]&gt; &lt;tibble [0 × 3]&gt;\n\nLASSO_grid[1, \".metrics\"][[1]]\n\n[[1]]\n# A tibble: 400 × 5\n    penalty .metric .estimator .estimate .config               \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;                 \n 1 1   e-10 rmse    standard       6062. Preprocessor1_Model001\n 2 1.12e-10 rmse    standard       6062. Preprocessor1_Model002\n 3 1.26e-10 rmse    standard       6062. Preprocessor1_Model003\n 4 1.41e-10 rmse    standard       6062. Preprocessor1_Model004\n 5 1.59e-10 rmse    standard       6062. Preprocessor1_Model005\n 6 1.78e-10 rmse    standard       6062. Preprocessor1_Model006\n 7 2.00e-10 rmse    standard       6062. Preprocessor1_Model007\n 8 2.25e-10 rmse    standard       6062. Preprocessor1_Model008\n 9 2.52e-10 rmse    standard       6062. Preprocessor1_Model009\n10 2.83e-10 rmse    standard       6062. Preprocessor1_Model010\n# ℹ 390 more rows\n\nLASSO_grid |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"rmse\")\n\n# A tibble: 200 × 7\n    penalty .metric .estimator  mean     n std_err .config               \n      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                 \n 1 1   e-10 rmse    standard   5475.    10    621. Preprocessor1_Model001\n 2 1.12e-10 rmse    standard   5475.    10    621. Preprocessor1_Model002\n 3 1.26e-10 rmse    standard   5475.    10    621. Preprocessor1_Model003\n 4 1.41e-10 rmse    standard   5475.    10    621. Preprocessor1_Model004\n 5 1.59e-10 rmse    standard   5475.    10    621. Preprocessor1_Model005\n 6 1.78e-10 rmse    standard   5475.    10    621. Preprocessor1_Model006\n 7 2.00e-10 rmse    standard   5475.    10    621. Preprocessor1_Model007\n 8 2.25e-10 rmse    standard   5475.    10    621. Preprocessor1_Model008\n 9 2.52e-10 rmse    standard   5475.    10    621. Preprocessor1_Model009\n10 2.83e-10 rmse    standard   5475.    10    621. Preprocessor1_Model010\n# ℹ 190 more rows\n\nLASSO_grid |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"rmse\") |&gt;\n  ggplot(aes(penalty, mean, color = .metric)) +\n  geom_line()\n\n\n\n\n\n\n\nlowest_rmse &lt;- LASSO_grid |&gt;\n  select_best(metric = \"rmse\")\nlowest_rmse\n\n# A tibble: 1 × 2\n       penalty .config               \n         &lt;dbl&gt; &lt;chr&gt;                 \n1 0.0000000001 Preprocessor1_Model001\n\nLASSO_wkf |&gt;\n  finalize_workflow(lowest_rmse)\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_dummy()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLinear Regression Model Specification (regression)\n\nMain Arguments:\n  penalty = 1e-10\n  mixture = 1\n\nComputational engine: glmnet \n\n#fit it to the entire training set to see the model fit\nLASSO_final &lt;- LASSO_wkf |&gt;\n  finalize_workflow(lowest_rmse) |&gt;\n  fit(data_training)\ntidy(LASSO_final)\n\n# A tibble: 14 × 3\n   term               estimate      penalty\n   &lt;chr&gt;                 &lt;dbl&gt;        &lt;dbl&gt;\n 1 (Intercept)         16899.  0.0000000001\n 2 sum_rain            -1843.  0.0000000001\n 3 sum_snow             -280.  0.0000000001\n 4 mean_temp            2777.  0.0000000001\n 5 mean_hum              -36.8 0.0000000001\n 6 mean_ws              -883.  0.0000000001\n 7 mean_vis             -222.  0.0000000001\n 8 mean_dpttemp            0   0.0000000001\n 9 mean_solrad          4072.  0.0000000001\n10 season_Spring       -1849.  0.0000000001\n11 season_Summer        -255.  0.0000000001\n12 season_Winter       -3035.  0.0000000001\n13 holiday_No.Holiday    782.  0.0000000001\n14 DOW_Weekend          -681.  0.0000000001\n\nLASSO_wkf |&gt;\n  finalize_workflow(lowest_rmse) |&gt;\n  last_fit(data_split) |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    6159.    Preprocessor1_Model1\n2 rsq     standard       0.647 Preprocessor1_Model1\n\nLASSO_final |&gt;\n  predict(data_test) |&gt;\n  pull() |&gt;\n  rmse_vec(truth = data_test$sum_rbc)\n\n[1] 6159.444"
  },
  {
    "objectID": "HW9.html#regression-tree-model",
    "href": "HW9.html#regression-tree-model",
    "title": "HW9",
    "section": "Regression Tree Model",
    "text": "Regression Tree Model\n\ntree_mod &lt;- decision_tree(tree_depth = tune(),\n                          min_n = 20,\n                          cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"regression\")\n\n\ntree_wkf &lt;- workflow() |&gt;\n  add_recipe(rec1) |&gt;\n  add_model(tree_mod)\n\ntemp &lt;- tree_wkf |&gt; \n  tune_grid(resamples = data_fold)\ntemp |&gt; \n  collect_metrics()\n\n# A tibble: 20 × 8\n   cost_complexity tree_depth .metric .estimator     mean     n  std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;  \n 1        3.51e- 2          6 rmse    standard   6043.       10 529.     Prepro…\n 2        3.51e- 2          6 rsq     standard      0.629    10   0.0572 Prepro…\n 3        2.86e- 9         13 rmse    standard   5822.       10 641.     Prepro…\n 4        2.86e- 9         13 rsq     standard      0.666    10   0.0574 Prepro…\n 5        7.60e- 4         14 rmse    standard   5824.       10 642.     Prepro…\n 6        7.60e- 4         14 rsq     standard      0.666    10   0.0572 Prepro…\n 7        2.71e- 6          4 rmse    standard   5951.       10 614.     Prepro…\n 8        2.71e- 6          4 rsq     standard      0.651    10   0.0556 Prepro…\n 9        3.61e- 6         12 rmse    standard   5822.       10 641.     Prepro…\n10        3.61e- 6         12 rsq     standard      0.666    10   0.0574 Prepro…\n11        1.48e- 8          2 rmse    standard   6051.       10 533.     Prepro…\n12        1.48e- 8          2 rsq     standard      0.629    10   0.0575 Prepro…\n13        1.92e- 7          3 rmse    standard   6054.       10 482.     Prepro…\n14        1.92e- 7          3 rsq     standard      0.642    10   0.0499 Prepro…\n15        1.23e- 4          9 rmse    standard   5817.       10 639.     Prepro…\n16        1.23e- 4          9 rsq     standard      0.667    10   0.0571 Prepro…\n17        1.14e-10          7 rmse    standard   5792.       10 653.     Prepro…\n18        1.14e-10          7 rsq     standard      0.667    10   0.0582 Prepro…\n19        5.20e- 3         10 rmse    standard   5841.       10 661.     Prepro…\n20        5.20e- 3         10 rsq     standard      0.665    10   0.0584 Prepro…\n\ntree_grid &lt;- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = c(10, 5))\n\ntree_fits &lt;- tree_wkf |&gt; \n  tune_grid(resamples = data_fold,\n            grid = tree_grid)\ntree_fits\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics           .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;             &lt;list&gt;          \n 1 &lt;split [245/28]&gt; Fold01 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [245/28]&gt; Fold02 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [245/28]&gt; Fold03 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [246/27]&gt; Fold04 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [246/27]&gt; Fold05 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [246/27]&gt; Fold06 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [246/27]&gt; Fold07 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [246/27]&gt; Fold08 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [246/27]&gt; Fold09 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [246/27]&gt; Fold10 &lt;tibble [100 × 6]&gt; &lt;tibble [0 × 3]&gt;\n\ntree_fits |&gt;\n  collect_metrics()\n\n# A tibble: 100 × 8\n   cost_complexity tree_depth .metric .estimator     mean     n  std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;  \n 1    0.0000000001          1 rmse    standard   7743.       10 528.     Prepro…\n 2    0.0000000001          1 rsq     standard      0.422    10   0.0642 Prepro…\n 3    0.000000001           1 rmse    standard   7743.       10 528.     Prepro…\n 4    0.000000001           1 rsq     standard      0.422    10   0.0642 Prepro…\n 5    0.00000001            1 rmse    standard   7743.       10 528.     Prepro…\n 6    0.00000001            1 rsq     standard      0.422    10   0.0642 Prepro…\n 7    0.0000001             1 rmse    standard   7743.       10 528.     Prepro…\n 8    0.0000001             1 rsq     standard      0.422    10   0.0642 Prepro…\n 9    0.000001              1 rmse    standard   7743.       10 528.     Prepro…\n10    0.000001              1 rsq     standard      0.422    10   0.0642 Prepro…\n# ℹ 90 more rows\n\ntree_fits %&gt;%\n  collect_metrics() %&gt;%\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(linewidth = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n\n\n\n\n\n\n\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"rmse\") |&gt;\n  arrange(mean)\n\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric .estimator  mean     n std_err .config    \n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;      \n 1    0.001                 8 rmse    standard   5800.    10    635. Preprocess…\n 2    0.0000000001          8 rmse    standard   5808.    10    636. Preprocess…\n 3    0.000000001           8 rmse    standard   5808.    10    636. Preprocess…\n 4    0.00000001            8 rmse    standard   5808.    10    636. Preprocess…\n 5    0.0000001             8 rmse    standard   5808.    10    636. Preprocess…\n 6    0.000001              8 rmse    standard   5808.    10    636. Preprocess…\n 7    0.00001               8 rmse    standard   5808.    10    636. Preprocess…\n 8    0.0001                8 rmse    standard   5808.    10    636. Preprocess…\n 9    0.001                11 rmse    standard   5813.    10    640. Preprocess…\n10    0.001                15 rmse    standard   5813.    10    640. Preprocess…\n# ℹ 40 more rows\n\ntree_best_params &lt;- select_best(tree_fits)\n\nWarning in select_best(tree_fits): No value of `metric` was given; \"rmse\" will\nbe used.\n\ntree_best_params\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1           0.001          8 Preprocessor1_Model28\n\ntree_final_wkf &lt;- tree_wkf |&gt;\n  finalize_workflow(tree_best_params)\n\ntree_final_fit &lt;- tree_final_wkf |&gt;\n  last_fit(data_split)\ntree_final_fit\n\n# Resampling results\n# Manual resampling \n# A tibble: 1 × 6\n  splits           id               .metrics .notes   .predictions .workflow \n  &lt;list&gt;           &lt;chr&gt;            &lt;list&gt;   &lt;list&gt;   &lt;list&gt;       &lt;list&gt;    \n1 &lt;split [273/92]&gt; train/test split &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;     &lt;workflow&gt;\n\ntree_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard    6042.    Preprocessor1_Model1\n2 rsq     standard       0.662 Preprocessor1_Model1\n\ntree_final_model &lt;- extract_workflow(tree_final_fit) \ntree_final_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_dummy()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 273 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n  1) root 273 28421670000 16898.510  \n    2) mean_temp&lt; -0.2742961 114  3245124000  8753.211  \n      4) season_Winter&gt;=0.5904959 67   239789500  5436.179  \n        8) mean_dpttemp&lt; -1.698966 17    20554600  4065.000 *\n        9) mean_dpttemp&gt;=-1.698966 50   176405500  5902.380  \n         18) sum_rain&gt;=-0.2815616 12    23154440  4187.833 *\n         19) sum_rain&lt; -0.2815616 38   106835200  6443.816 *\n      5) season_Winter&lt; 0.5904959 47  1217279000 13481.740  \n       10) season_Spring&gt;=0.567894 27   383579600 10605.370  \n         20) sum_rain&gt;=-0.2620276 9    83005710  6822.111 *\n         21) sum_rain&lt; -0.2620276 18   107347700 12497.000 *\n       11) season_Spring&lt; 0.567894 20   308743900 17364.850  \n         22) mean_solrad&lt; -0.7567304 7    74999870 13422.860 *\n         23) mean_solrad&gt;=-0.7567304 13    66397680 19487.460 *\n    3) mean_temp&gt;=-0.2742961 159 12190290000 22738.530  \n      6) mean_solrad&lt; -0.5125701 29  1601248000 11379.720  \n       12) mean_temp&lt; 0.9015514 19   891515500  8659.737 *\n       13) mean_temp&gt;=0.9015514 10   302084000 16547.700 *\n      7) mean_solrad&gt;=-0.5125701 130  6012714000 25272.420  \n       14) mean_temp&lt; 0.3677366 36  1932565000 21937.670  \n         28) mean_ws&gt;=0.6970799 7   779828200 15926.000 *\n         29) mean_ws&lt; 0.6970799 29   838691300 23388.760  \n           58) mean_hum&gt;=0.03728552 7   549959800 19792.860 *\n           59) mean_hum&lt; 0.03728552 22   169418200 24532.910  \n            118) mean_dpttemp&lt; -0.1528358 7    27749070 21802.860 *\n            119) mean_dpttemp&gt;=-0.1528358 15    65149810 25806.930 *\n       15) mean_temp&gt;=0.3677366 94  3526488000 26549.550  \n         30) mean_temp&gt;=1.411176 21   180006000 21936.620 *\n         31) mean_temp&lt; 1.411176 73  2771070000 27876.560  \n           62) mean_solrad&lt; 0.2954843 18  1570192000 23004.830 *\n           63) mean_solrad&gt;=0.2954843 55   633857000 29470.950  \n            126) mean_temp&lt; 0.5930847 13   175173600 26856.310 *\n            127) mean_temp&gt;=0.5930847 42   342303100 30280.240  \n              254) mean_temp&gt;=1.043053 12    43709990 27715.330 *\n              255) mean_temp&lt; 1.043053 30   188070300 31306.200  \n                510) season_Summer&lt; 0.567894 14    35117060 29866.000 *\n                511) season_Summer&gt;=0.567894 16    98506150 32566.380 *"
  },
  {
    "objectID": "HW9.html#bagged-tree-model",
    "href": "HW9.html#bagged-tree-model",
    "title": "HW9",
    "section": "Bagged Tree Model",
    "text": "Bagged Tree Model\n\nbag_spec &lt;- bag_tree(tree_depth = 5, min_n = 10, cost_complexity = tune()) |&gt;\n set_engine(\"rpart\") |&gt;\n set_mode(\"regression\")\n\n\n\nbag_wkf &lt;- workflow() |&gt;\n add_recipe(rec1) |&gt;\n add_model(bag_spec)\n\nbag_fit &lt;- bag_wkf |&gt;\n tune_grid(resamples = data_fold,\n grid = grid_regular(cost_complexity(),\n levels = 15),\n metrics = metric_set(rmse))\nbag_fit\n\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits           id     .metrics          .notes          \n   &lt;list&gt;           &lt;chr&gt;  &lt;list&gt;            &lt;list&gt;          \n 1 &lt;split [245/28]&gt; Fold01 &lt;tibble [15 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 2 &lt;split [245/28]&gt; Fold02 &lt;tibble [15 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 3 &lt;split [245/28]&gt; Fold03 &lt;tibble [15 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 4 &lt;split [246/27]&gt; Fold04 &lt;tibble [15 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 5 &lt;split [246/27]&gt; Fold05 &lt;tibble [15 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 6 &lt;split [246/27]&gt; Fold06 &lt;tibble [15 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 7 &lt;split [246/27]&gt; Fold07 &lt;tibble [15 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 8 &lt;split [246/27]&gt; Fold08 &lt;tibble [15 × 5]&gt; &lt;tibble [0 × 3]&gt;\n 9 &lt;split [246/27]&gt; Fold09 &lt;tibble [15 × 5]&gt; &lt;tibble [0 × 3]&gt;\n10 &lt;split [246/27]&gt; Fold10 &lt;tibble [15 × 5]&gt; &lt;tibble [0 × 3]&gt;\n\nbag_fit |&gt;\n collect_metrics() |&gt;\n filter(.metric == \"rmse\") |&gt;\n arrange(mean)\n\n# A tibble: 15 × 7\n   cost_complexity .metric .estimator  mean     n std_err .config              \n             &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;                \n 1        7.20e- 7 rmse    standard   4849.    10    635. Preprocessor1_Model07\n 2        1.93e- 9 rmse    standard   4931.    10    615. Preprocessor1_Model03\n 3        1.18e- 3 rmse    standard   4935.    10    697. Preprocessor1_Model12\n 4        1   e-10 rmse    standard   4950.    10    649. Preprocessor1_Model01\n 5        1.64e- 7 rmse    standard   4989.    10    630. Preprocessor1_Model06\n 6        8.48e- 9 rmse    standard   5025.    10    677. Preprocessor1_Model04\n 7        1.39e- 5 rmse    standard   5036.    10    642. Preprocessor1_Model09\n 8        2.68e- 4 rmse    standard   5072.    10    631. Preprocessor1_Model11\n 9        4.39e-10 rmse    standard   5080.    10    594. Preprocessor1_Model02\n10        5.18e- 3 rmse    standard   5081.    10    602. Preprocessor1_Model13\n11        3.73e- 8 rmse    standard   5131.    10    578. Preprocessor1_Model05\n12        3.16e- 6 rmse    standard   5264.    10    574. Preprocessor1_Model08\n13        6.11e- 5 rmse    standard   5274.    10    608. Preprocessor1_Model10\n14        2.28e- 2 rmse    standard   5514.    10    575. Preprocessor1_Model14\n15        1   e- 1 rmse    standard   6245.    10    505. Preprocessor1_Model15\n\nbag_best_params &lt;- select_best(bag_fit)\n\nWarning in select_best(bag_fit): No value of `metric` was given; \"rmse\" will be\nused.\n\nbag_best_params\n\n# A tibble: 1 × 2\n  cost_complexity .config              \n            &lt;dbl&gt; &lt;chr&gt;                \n1     0.000000720 Preprocessor1_Model07\n\nbag_final_wkf &lt;- bag_wkf |&gt;\n finalize_workflow(bag_best_params)\nbag_final_fit &lt;- bag_final_wkf |&gt;\n last_fit(data_split, metrics = metric_set(rmse))\n\nbag_final_fit|&gt;collect_metrics()\n\n# A tibble: 1 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       5461. Preprocessor1_Model1"
  },
  {
    "objectID": "HW9.html#random-forest-model",
    "href": "HW9.html#random-forest-model",
    "title": "HW9",
    "section": "Random Forest Model",
    "text": "Random Forest Model\n\nrf_spec &lt;- rand_forest(mtry = tune()) |&gt;\n set_engine(\"ranger\") |&gt;\n set_mode(\"regression\")\n\nrf_wkf &lt;- workflow() |&gt;\n add_recipe(rec1) |&gt;\n add_model(rf_spec)\n\nrf_fit &lt;- rf_wkf |&gt;\n tune_grid(resamples = data_fold,\n grid = 7,\n metrics = metric_set(rmse))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\nrf_fit |&gt;\n collect_metrics() |&gt;\n filter(.metric == \"rmse\") |&gt;\n arrange(mean)\n\n# A tibble: 7 × 7\n   mtry .metric .estimator  mean     n std_err .config             \n  &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1    13 rmse    standard   4757.    10    626. Preprocessor1_Model5\n2    10 rmse    standard   4765.    10    614. Preprocessor1_Model7\n3     9 rmse    standard   4783.    10    625. Preprocessor1_Model1\n4     6 rmse    standard   4840.    10    612. Preprocessor1_Model3\n5     5 rmse    standard   4871.    10    609. Preprocessor1_Model4\n6     4 rmse    standard   4889.    10    600. Preprocessor1_Model2\n7     2 rmse    standard   5137.    10    559. Preprocessor1_Model6\n\nrf_best_params &lt;- select_best(rf_fit)\n\nWarning in select_best(rf_fit): No value of `metric` was given; \"rmse\" will be\nused.\n\nrf_best_params\n\n# A tibble: 1 × 2\n   mtry .config             \n  &lt;int&gt; &lt;chr&gt;               \n1    13 Preprocessor1_Model5\n\nrf_final_wkf &lt;- rf_wkf |&gt;\n finalize_workflow(rf_best_params)\nrf_final_fit &lt;- rf_final_wkf |&gt;\n last_fit(data_split, metrics = metric_set(rmse))\n\nrf_final_fit |&gt; collect_metrics()\n\n# A tibble: 1 × 4\n  .metric .estimator .estimate .config             \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 rmse    standard       5201. Preprocessor1_Model1"
  }
]